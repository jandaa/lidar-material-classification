

# general parameters
dataset_path: ??? # Must be provided at command line

# Set output directory
hydra:
  run:
    dir: outputs/random_forest

# What tasks to run, Options
# 1. train - train and run on test set
# 2. eval - run on test set
# 3. visualize - generate visualization output
tasks:
  - train

# Trainer configuration
accelerator: gpu
strategy: ddp
devices: [0]
max_epochs: 1000
max_steps:
max_time: # Format DD:HH:MM:SS
check_val_every_n_epoch: 5
val_check_interval: 1.0
precision: 32

# Fraction of training set to use during training
limit_train_batches: 1.0
limit_val_batches: 1.0
limit_test_batches: 1.0

# Continue training from specific checkpoint
# set to last.ckpt to use the latest checkpoint
checkpoint:

# Set names of dataset paths
data:
  raw_path: data
  preprocessed_path: preprocessed
  point_cloud_path: point_clouds
  ignore_label: -1
  materials:
    [
      "aluminum",
      "wood",
      "black",
      "black_cloth",
      "unknown"
    ]

preprocess:
  max_angle_in_deg: -1

model:
  input_size: 1 # 256
  output_size: 1
  kernel_size: 7
  dropout: 0.05
  channels: [32, 32, 32, 64, 64, 64, 128, 128]

train:
  train_split: 0.8
  random_seed: 42
  accumulate_grad_batches: 1
  batch_size: 256
  train_workers: 12

optimizer:
  type: Adam # Adam or SGD
  lr: 2e-3 # 1e-1
  momentum: 0.9
  dampening: 0.1
  weight_decay: 0.0001

scheduler:
  type: PolyLR
  exp_gamma:
  poly_power: 0.9
  max_iter: 60000
  interval: step
  frequency: 10
